{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_warn_always(False)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datasets import load_dataset, DatasetDict, concatenate_datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc05b465b944c17a87def5391b7ca34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c993abdf89c0416eba545422396ce99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44047f17c8504e8ba5d3227d3bae97b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b00ecdb73ac41ff8ffb5d45ff0086a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6165 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f75b86acfd4a6fb0209fe5431870b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2733 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af3aaac6b224496831fb02aa37305f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92fe50093a4428487d9f53c6f109f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/138384 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46464396b5114934a13d7ae511680457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17944 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126ff43866804cef811801b43edbda11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17210 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}\n",
      "{'question': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'answers': {'answer_start': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'text': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}}\n",
      "{'question': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'answers': {'answer_start': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'text': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94e251f4d6b4223845ca332a33ff701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/6165 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6bd5510e0344cf9a5d7b402b74f327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/2733 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc30a6206ed04dc4aff7efcb98559c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/20360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41999af1563645cdb8b1cfbd80c75043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/138384 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7b14f49667471ab5450bd25fc58808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/17944 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2cf98619a34b3c9ceb1a8310294f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/17210 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'question', 'context', 'answers'],\n",
      "        num_rows: 246343\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'question', 'context', 'answers'],\n",
      "        num_rows: 31247\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict, concatenate_datasets, Features, Value, Sequence\n",
    "\n",
    "# Preprocess SQuAD\n",
    "def preprocess_squad(examples):\n",
    "    return {\n",
    "        \"id\": examples[\"id\"],\n",
    "        \"question\": examples[\"question\"],\n",
    "        \"context\": examples[\"context\"],\n",
    "        \"answers\": \n",
    "            {\"text\": examples[\"answers\"][\"text\"], \"answer_start\": [int(start) for start in examples[\"answers\"][\"answer_start\"]]}\n",
    "    }\n",
    "\n",
    "# Preprocess WikiQA\n",
    "def preprocess_wikiqa(examples):\n",
    "    # answers = {\"text\": examples[\"answer\"], \"answer_start\": [0] * len(examples[\"answer\"])}\n",
    "    answers = {\"text\": [examples[\"answer\"]] if isinstance(examples[\"answer\"], str) else examples[\"answer\"],\n",
    "           \"answer_start\": [0] * len(examples[\"answer\"])}\n",
    "    return {\n",
    "        \"id\": examples[\"question_id\"],\n",
    "        \"question\": examples[\"question\"],\n",
    "        \"context\": examples[\"document_title\"],\n",
    "        \"answers\": answers,\n",
    "    }\n",
    "\n",
    "# Preprocess TriviaQA\n",
    "def preprocess_triviaqa(examples):\n",
    "    context = \", \".join(examples[\"entity_pages\"][\"wiki_context\"]) or \", \".join(examples[\"search_results\"][\"search_context\"])\n",
    "    answer_text = examples[\"answer\"][\"normalized_value\"]\n",
    "    answer_start = context.find(answer_text) if answer_text in context else -1\n",
    "    # answers = {\"text\": answer_text, \"answer_start\": [int(answer_start)]}  # Ensure answer_start is int32\n",
    "    answers = {\"text\": [answer_text], \"answer_start\": [int(answer_start)]}\n",
    "    return {\n",
    "        \"id\": examples[\"question_id\"],\n",
    "        \"question\": examples[\"question\"],\n",
    "        \"context\": context,\n",
    "        \"answers\": answers,\n",
    "    }\n",
    "\n",
    "# Load datasets and preprocess\n",
    "squad = load_dataset(\"squad\")\n",
    "wikiqa = load_dataset(\"wiki_qa\")\n",
    "triviaqa = load_dataset(\"trivia_qa\", \"rc\")\n",
    "\n",
    "squad = squad.map(preprocess_squad)\n",
    "wikiqa = wikiqa.map(preprocess_wikiqa)\n",
    "triviaqa = triviaqa.map(preprocess_triviaqa)\n",
    "\n",
    "squad = squad.remove_columns([\"title\"])\n",
    "wikiqa = wikiqa.remove_columns([\"question_id\", \"document_title\", \"answer\", \"label\"])\n",
    "triviaqa = triviaqa.remove_columns(['question_id', 'question_source', 'entity_pages', 'search_results', 'answer'])\n",
    "\n",
    "# Ensure all datasets share the same features schema\n",
    "common_features = Features({\n",
    "    \"id\": Value(\"string\"),\n",
    "    \"question\": Value(\"string\"),\n",
    "    \"context\": Value(\"string\"),\n",
    "    \"answers\": Sequence(\n",
    "        {\n",
    "            \"text\": Value(\"string\"),\n",
    "            \"answer_start\": Value(\"int32\")\n",
    "        }\n",
    "    )\n",
    "})\n",
    "\n",
    "print(squad[\"train\"].features)\n",
    "print(wikiqa[\"train\"].features)\n",
    "print(triviaqa[\"train\"].features)\n",
    "\n",
    "\n",
    "# Cast datasets to common schema\n",
    "squad = squad.cast(common_features)\n",
    "wikiqa = wikiqa.cast(common_features)\n",
    "triviaqa = triviaqa.cast(common_features)\n",
    "\n",
    "# Combine datasets\n",
    "qa_datasets = DatasetDict({\n",
    "    \"train\": concatenate_datasets([squad[\"train\"], wikiqa[\"train\"], triviaqa[\"train\"]]),\n",
    "    \"validation\": concatenate_datasets([squad[\"validation\"], wikiqa[\"validation\"], triviaqa[\"validation\"]]),\n",
    "})\n",
    "\n",
    "print(qa_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(qa_datasets[\"train\"].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}\n"
     ]
    }
   ],
   "source": [
    "print(squad[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BO import iterative_loop, get_BO_plots\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "\n",
    "def run_BO(all_loaders, validaton_dataloader, iterations, num_epochs=20, printout=False):\n",
    "    print(\"running BO...\")\n",
    "    X, observations, gp = iterative_loop(all_loaders, validaton_dataloader, num_epochs=num_epochs, iterations=iterations, printout=printout)\n",
    "    BO_to_plot = get_BO_plots(observations) # BO results\n",
    "    naive_combine = BO_to_plot[0] # naive mixing result is the first iteration result of BO\n",
    "\n",
    "    # plot model performance as BO progresses...\n",
    "    plt.plot(range(len(BO_to_plot)), BO_to_plot, c=\"blue\", alpha=0.3, label=\"BO on mixing ratio\")\n",
    "    plt.axhline(naive_combine, linestyle=\"--\", c=\"red\", label=\"sample from each data source equally\")\n",
    "    plt.xlabel(\"BO iterations\")\n",
    "    plt.ylabel(\"accuracy on evaluation task\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # plot posterior\n",
    "    # posterior_acc = []\n",
    "    # for x in np.linspace(0,1,100):\n",
    "    #     posterior_acc.append(gp.posterior(torch.Tensor([[x,1-x]])).mean.item())\n",
    "        \n",
    "    # plt.plot(np.linspace(0,1,100), posterior_acc)\n",
    "    # plt.xlabel(\"mixing ratio (percentage on cats and dogs)\")\n",
    "    # plt.ylabel(\"accuracy\")\n",
    "    # plt.title(\"evaluation ratio : 1.0 cats and dogs\")\n",
    "    # plt.show()\n",
    "\n",
    "    def get_optimal_mixture_from_GP_posterior():\n",
    "        UCB = UpperConfidenceBound(gp, beta=0.0)\n",
    "        bounds = torch.stack([torch.zeros(len(all_loaders)), torch.ones(len(all_loaders))]) # need to change the bounds for parameters\n",
    "        A = [1.0] * len(all_loaders)\n",
    "        x = list(range(len(all_loaders)))\n",
    "        candidate, acq_value = optimize_acqf(\n",
    "            UCB, bounds=bounds, q=1, num_restarts=20, raw_samples=30,\n",
    "            equality_constraints = [(torch.tensor(x), torch.tensor(A), 1)]\n",
    "        )\n",
    "        return candidate\n",
    "    \n",
    "\n",
    "    def get_best_observation_mixture():\n",
    "        \n",
    "        # Find the index in list B that has the highest value\n",
    "        highest_index = observations.index(max(observations))\n",
    "        \n",
    "        # Return the corresponding item in list A\n",
    "        return X[highest_index]\n",
    "\n",
    "    \n",
    "    print(\"best mixture found in BO iterations is: \", get_best_observation_mixture())\n",
    "    \n",
    "    return X, observations, gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
